{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PSDA_BonusTask.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CUyrkD5C6-of","colab_type":"text"},"source":["# Mount Drive"]},{"cell_type":"code","metadata":{"id":"KcBdKy5qsE2E","colab_type":"code","outputId":"a0c371ce-cdd7-4bcd-cb6f-ffb20804608b","executionInfo":{"status":"ok","timestamp":1589137050076,"user_tz":-120,"elapsed":848,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","basedir = '/content/drive/My Drive/PSDA Group 4/Data/' "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jnP4wNp77ULV","colab_type":"text"},"source":["# Dependencies\n","\n"]},{"cell_type":"code","metadata":{"id":"zTgec0k_yrjY","colab_type":"code","colab":{}},"source":["!pip install gama\n","!apt-get install swig -y\n","!pip install Cython numpy\n","!pip install auto-sklearn\n","!pip freeze > req.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRYtYm_zrU4q","colab_type":"code","colab":{}},"source":["from gama import GamaClassifier\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import log_loss, accuracy_score\n","import logging\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","import autosklearn.classification"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BADLFyKQ7YFs","colab_type":"text"},"source":["# Read Data"]},{"cell_type":"code","metadata":{"id":"aNVWxsZsr8LA","colab_type":"code","outputId":"2e629076-0158-4efd-f369-60211d3d46e7","executionInfo":{"status":"ok","timestamp":1589137114763,"user_tz":-120,"elapsed":1666,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#This dataset tells which of the users purchased/not purchased a particular product\n","df = pd.read_csv(basedir+'Social_Network_Ads.csv')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User ID</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>EstimatedSalary</th>\n","      <th>Purchased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15624510</td>\n","      <td>Male</td>\n","      <td>19</td>\n","      <td>19000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15810944</td>\n","      <td>Male</td>\n","      <td>35</td>\n","      <td>20000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15668575</td>\n","      <td>Female</td>\n","      <td>26</td>\n","      <td>43000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15603246</td>\n","      <td>Female</td>\n","      <td>27</td>\n","      <td>57000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15804002</td>\n","      <td>Male</td>\n","      <td>19</td>\n","      <td>76000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    User ID  Gender  Age  EstimatedSalary  Purchased\n","0  15624510    Male   19            19000          0\n","1  15810944    Male   35            20000          0\n","2  15668575  Female   26            43000          0\n","3  15603246  Female   27            57000          0\n","4  15804002    Male   19            76000          0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"qAUKYGwa9Fqs","colab_type":"text"},"source":["# Data Partitioning"]},{"cell_type":"code","metadata":{"id":"iFjdZQsdswmN","colab_type":"code","colab":{}},"source":["X = df.iloc[:, [2, 3]].values\n","y = df.iloc[:, 4].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KJJ9c6Bsh7L","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWB6KSRO9Osu","colab_type":"text"},"source":["# Auto ML"]},{"cell_type":"markdown","metadata":{"id":"FoHkTqUPsEj7","colab_type":"text"},"source":["Wählen Sie ein AutoML Package. Begründen Sie Ihre Auswahl."]},{"cell_type":"markdown","metadata":{"id":"V4Wd_cPnsFb1","colab_type":"text"},"source":["We chose to use autosklearn, since it is a drop-in replacement for a scikit-learn estimator, which most of the ML researchers are familiar with. Furthermore it provides us with APIs that can be used to inspect the statistics and the models used. These logs can be used to obtain insights on the behaviour of the search procedure.\n","\n","We also decided to test out gama, another ML package, which is very similar to autosklearn."]},{"cell_type":"markdown","metadata":{"id":"_aDXIc0atVIA","colab_type":"text"},"source":[" Führen Sie die Klassifikationsaufgabe von Aufgabe 7 mit AutoML durch. Vergleichen Sie die\n","Ergebnisse mit den Ergebnissen aus Aufgabe 7"]},{"cell_type":"code","metadata":{"id":"j5DrWTOhye4B","colab_type":"code","colab":{}},"source":["automl = autosklearn.classification.AutoSklearnClassifier()\n","automl.fit(X_train, y_train)\n","y_hat = automl.predict(X_test)\n","print(\"Accuracy score\", accuracy_score(y_test, y_hat))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4lXN03m1ggw","colab_type":"code","outputId":"ecce3eed-7efb-4713-e21c-048a493b5802","executionInfo":{"status":"ok","timestamp":1589053678531,"user_tz":-120,"elapsed":897362,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# configure auto-sklearn\n","automl = autosklearn.classification.AutoSklearnClassifier(\n","          time_left_for_this_task=900, # run auto-sklearn for at most 2min\n","          per_run_time_limit=100, # spend at most 30 sec for each model training\n","          )\n","\n","# train model(s)\n","automl.fit(X_train, y_train)\n","\n","# evaluate\n","y_hat = automl.predict(X_test)\n","test_acc = accuracy_score(y_test, y_hat)\n","print(\"Test Accuracy score {0}\".format(test_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Accuracy score 0.8625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7nOQjt_-1rcL","colab_type":"code","colab":{}},"source":["print(automl.sprint_statistics())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKmdNdEd1sWA","colab_type":"code","colab":{}},"source":["print(automl.show_models())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cexTUz4Os1fu","colab_type":"code","outputId":"66e8b76b-e266-474e-9e68-f171e66132a6","executionInfo":{"status":"ok","timestamp":1589049399824,"user_tz":-120,"elapsed":162399,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["automl = GamaClassifier(max_total_time=180, keep_analysis_log=None)\n","print(\"Starting `fit` which will take roughly 3 minutes.\")\n","automl.fit(X_train, y_train)\n","\n","label_predictions = automl.predict(X_test)\n","probability_predictions = automl.predict_proba(X_test)\n","\n","print('accuracy:', accuracy_score(y_test, label_predictions))\n","print('log loss:', log_loss(y_test, probability_predictions))\n","# the `score` function outputs the score on the metric optimized towards (by default, `log_loss`)\n","print('log_loss', automl.score(X_test, y_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting `fit` which will take roughly 3 minutes.\n","accuracy: 0.8625\n","log loss: 0.3590357913678016\n","log_loss 0.3590357913678016\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pe8lyo2YueAB","colab_type":"code","outputId":"509c0c0f-fdf3-457f-d099-60a5b0ed1104","executionInfo":{"status":"ok","timestamp":1589050073010,"user_tz":-120,"elapsed":946,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["automl = GamaClassifier(\n","    max_total_time=400, # in seconds\n","    n_jobs=2,  # one subprocess\n","    scoring='accuracy',  # metric to optimize for\n","    verbosity=logging.INFO,  # to get printed updates about search progress\n","    keep_analysis_log=\"trees.log\",  # name for a log file to record search output in\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using GAMA version 20.2.0.\n","GamaClassifier(cache=None,post_processing_method=BestFitPostProcessing(),search_method=AsyncEA(),keep_analysis_log=/content/trees.log,verbosity=20,n_jobs=2,max_eval_time=None,max_total_time=400,random_state=None,max_pipeline_length=None,regularize_length=True,scoring=accuracy)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yb9iaYptu6al","colab_type":"code","outputId":"e2134cbf-e797-434f-8bee-82b5f4d56e7b","executionInfo":{"status":"ok","timestamp":1589050434272,"user_tz":-120,"elapsed":360218,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["automl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["preprocessing took 0.0051s.\n","Starting EA with new population.\n","Search phase evaluated 946 individuals.\n","search took 359.0476s.\n","postprocess took 0.1441s.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yYZXOnUJvky_","colab_type":"code","outputId":"1a974463-2525-4ead-f28e-bf848aee28e8","executionInfo":{"status":"ok","timestamp":1589050448135,"user_tz":-120,"elapsed":983,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["automl.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8625"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"X8AtqL6u9Ve4","colab_type":"text"},"source":["# Best Model of Task 7"]},{"cell_type":"code","metadata":{"id":"JrGKDVDEwXM-","colab_type":"code","colab":{}},"source":["X_train = StandardScaler().fit_transform(X_train)\n","X_test = StandardScaler().fit_transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBoAbDjJwX33","colab_type":"code","colab":{}},"source":["param_grid_svc = [{'C': [1,10,100, 1000], 'kernel': ['linear'], },\n","              {'C': [1,10,100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}]\n","search_svm = GridSearchCV(SVC(random_state=1), param_grid_svc, scoring='accuracy', cv=10, n_jobs=-1)\n","search_svm = search_svm.fit(X_train, y_train)\n","best_score_svm = search_svm.best_score_\n","best_parameters_svm = search_svm.best_params_\n","scores_svm = search_svm.cv_results_\n","Data_svm = pd.DataFrame(scores_svm)\n","# Data_svm\n","# Data_svm[['params', 'mean_test_score', 'mean_score_time', 'rank_test_score' ]].to_csv(\"./svm.dat\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWOeWczFwxGn","colab_type":"code","outputId":"a9e3178f-e99b-4d12-bc68-9291e49e241e","executionInfo":{"status":"ok","timestamp":1589050022212,"user_tz":-120,"elapsed":1001,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["best_parameters_svm"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 1, 'gamma': 0.6, 'kernel': 'rbf'}"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"Rd35kBJvwzCg","colab_type":"code","outputId":"ebf525df-2029-4809-9b10-8b7aa25c979e","executionInfo":{"status":"ok","timestamp":1589050037985,"user_tz":-120,"elapsed":1012,"user":{"displayName":"Gerrit Merz","photoUrl":"","userId":"17174744278973723577"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["best_score_svm"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.928125"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"GK55ZMChvPY4","colab_type":"text"},"source":["By looking at the scores, we can see that our model of task 7 outperforms the automl packages. Even when running autosklearn for more than 20 minutes it only achieve a test accuracy score of 0.8625."]},{"cell_type":"markdown","metadata":{"id":"cqBg1cXC9gLa","colab_type":"text"},"source":["# Our Opinion on Auto ML"]},{"cell_type":"markdown","metadata":{"id":"rzSr4ySDtLWV","colab_type":"text"},"source":["Was ist Ihre Meinung zu AutoML?"]},{"cell_type":"markdown","metadata":{"id":"IWfZBY24tN_c","colab_type":"text"},"source":["In general we think that automl packages are useful when working on ML projects. They give us a good and fast overview of what scores are achievable. Also, they are very suitable if the ML researcher has limited knowledge in how to use pipelines that include pre-processing steps such as scaling etc. Hence, they are suitable if it is only necessary to predict the outcome. If the researchers want to get further insights about the data distribution, collinearity, etc. the use of \"traditional\" ML models might be more insightful. Furthermore, in our case example we can see that automl packages (we tried autosklearn and gama) don't necessarily show you the best achievable results, even when running for a longer time."]}]}