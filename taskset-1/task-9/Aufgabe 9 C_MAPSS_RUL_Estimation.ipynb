{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *To be done*\n",
    "\n",
    "- Add data set visualizations\n",
    "- Is there any other way to define target lable (RUL)?\n",
    "- Use other data sets FD002..004\n",
    "- Add Logistic Rregression and/or SVM\n",
    "\n",
    "- Publish on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e96OGEl07oXG"
   },
   "source": [
    "# Mount Google Drive\n",
    "~~In this example, the data is saved in the folder of personal google drive.~~\n",
    "\n",
    "~~First you have to upload the data to your google drive, then connect the drive~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skgwbdhJ2aEl"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CG_U0Y9w72ze"
   },
   "source": [
    "# Install Python Packages\n",
    "~~Although most of the commonly used Python libraries are pre-installed, new libraries can be installed using the below packages~~~\n",
    "\n",
    "!pip install [package name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGHEFxAJ9oqF"
   },
   "outputs": [],
   "source": [
    "#!pip install tsfresh\n",
    "# tsfresh is a python package, which automatically calculates a large number of time series characteristics (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A67lPTNHJkGs"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boLQLTsdJjY6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['ytick.labelsize'] = \"x-large\"\n",
    "plt.rcParams['xtick.labelsize'] = \"x-large\"\n",
    "plt.rcParams['axes.labelsize'] = \"x-large\"\n",
    "plt.rcParams['figure.titlesize'] = \"x-large\"\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wb00bcxu9tih"
   },
   "source": [
    "# Data Description\n",
    "C-MAPSS data set which contains turbofan engine degradation data is a widely used prognostic benchmark data for predicting the Remaining useful life (RUL). This data set is simulated by the tool Commercial Modular Aero Propulsion System Simulation (C-MAPSS) developed by NASA. Run to failure simulations were performed for engines with varying degrees of initial wear but in a healthy state. During each cycle in the simulation, one sample of all 21 sensors such as physical core speed, temperature at fan inlet and pressure at fan inlet etc will be recorded once. As the simulation progresses, the performance of the turbofan engine degrades until it loses functionality. \n",
    "\n",
    "C-MAPSS data consists of four sub-data sets with different operational conditions and fault patterns. \n",
    "\n",
    "|         Dataset        | FD001 | FD002 | FD003 | FD004 |\n",
    "|:----------------------:|:-----:|:-----:|:-----:|:-----:|\n",
    "|      Training set      |  100  |  260  |  100  |  249  |\n",
    "|        Test set        |  100  |  259  |  100  |  248  |\n",
    "| Operational conditions |   1   |   6   |   1   |   6   |\n",
    "| Fault conditions       | 1     | 1     | 2     | 2     |\n",
    "\n",
    "\n",
    "As shown Table above, each sub-data set has been split into a training set and a test set. The training sets contain sensor records for all cycles in the run to failure simulation. Unlike the training sets, the test sets only contain partial temporal sensor records which stopped at a time prior to the failure. The task is to predict the RUL of each engine in the test sets by using the training sets with the given sensor records. The corresponding RUL to test sets has been provided. With this, the performance of the model can be verified. \n",
    "\n",
    "The data provieded as text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:\n",
    "\n",
    "unit number\n",
    "\n",
    "time, in cycles\n",
    "\n",
    "operational setting 1\n",
    "\n",
    "operational setting 2\n",
    "\n",
    "operational setting 3\n",
    "\n",
    "sensor measurement 1\n",
    "\n",
    "sensor measurement 2 \n",
    "\n",
    "sensor measurement 3 \n",
    "\n",
    "...\n",
    "\n",
    "sensor measurement 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLw-w1TDE9Zo"
   },
   "source": [
    "# Data Exploration and Preparation\n",
    "take FD001 as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAmDXiZU2mkK"
   },
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "Path_to_data = \"CMAPSSData/\"\n",
    "\n",
    "column_name = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "               's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "               's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "# training data set\n",
    "train_FD001 = pd.read_table(Path_to_data+\"train_FD001.txt\", header=None, delim_whitespace=True)\n",
    "train_FD001.columns = column_name\n",
    "\n",
    "# test data set\n",
    "test_FD001 = pd.read_table(Path_to_data+\"test_FD001.txt\", header=None, delim_whitespace=True)\n",
    "test_FD001.columns = column_name\n",
    "\n",
    "# RUL for test data set\n",
    "RUL_FD001 = pd.read_table(Path_to_data+\"RUL_FD001.txt\", header=None, delim_whitespace=True)\n",
    "\n",
    "train_FD001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2R6-hIDIJZu"
   },
   "source": [
    "In this sub dataset we have **100** engines (engine_id) which are monitored over time (cycle). Each engine had operational_settings and sensor_measurements recorded for each cycle. The RUL is the amount of cycles an engine has left before it needs maintenance. What makes this data set special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7z2IzRdSIdDk"
   },
   "outputs": [],
   "source": [
    "def add_RUL(col):\n",
    "    # Reverse the cycle evolution, where remaining time of a machine is 0 at the failure.\n",
    "    # It is assumed here that the state of the machine is linearly deteriorating\n",
    "    return col[::-1]-1\n",
    "# Calculate RUL for each time point of each engine  \n",
    "train_FD001['rul'] = train_FD001[['engine_id', 'cycle']].groupby('engine_id').transform(add_RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQMbZSIAE1aU"
   },
   "source": [
    "**Is there any other way to define target lable (RUL) ?**\n",
    "\n",
    "We are also going to load and explore the other three data sets available now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD002 = pd.read_table(Path_to_data+\"train_FD002.txt\", header=None, delim_whitespace=True)\n",
    "train_FD002.columns = column_name\n",
    "RUL_FD002 = pd.read_table(Path_to_data+\"RUL_FD002.txt\", header=None, delim_whitespace=True)\n",
    "train_FD002['rul'] = train_FD002[['engine_id', 'cycle']].groupby('engine_id').transform(add_RUL)\n",
    "\n",
    "train_FD003 = pd.read_table(Path_to_data+\"train_FD003.txt\", header=None, delim_whitespace=True)\n",
    "train_FD003.columns = column_name\n",
    "RUL_FD003 = pd.read_table(Path_to_data+\"RUL_FD003.txt\", header=None, delim_whitespace=True)\n",
    "train_FD003['rul'] = train_FD003[['engine_id', 'cycle']].groupby('engine_id').transform(add_RUL)\n",
    "\n",
    "train_FD004 = pd.read_table(Path_to_data+\"train_FD004.txt\", header=None, delim_whitespace=True)\n",
    "train_FD004.columns = column_name\n",
    "RUL_FD004 = pd.read_table(Path_to_data+\"RUL_FD002.txt\", header=None, delim_whitespace=True)\n",
    "train_FD004['rul'] = train_FD004[['engine_id', 'cycle']].groupby('engine_id').transform(add_RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s start with visualizing intersting aspects to start out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfBy89S6P4kJ"
   },
   "outputs": [],
   "source": [
    "# Visualize the RUL curve of some engines (1,2,3,4,5,6)\n",
    "g = sns.PairGrid(data=train_FD001.reset_index().query('engine_id < 7') ,\n",
    "                 x_vars=[\"index\"],\n",
    "                 y_vars=['rul'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g = g.map(plt.plot, alpha=1)\n",
    "g = g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the same for the other training data sets avaiable, look at more engines\n",
    "g1 = sns.PairGrid(data=train_FD002.reset_index().query('engine_id < 20') ,\n",
    "                 x_vars=[\"index\"],\n",
    "                 y_vars=['rul'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g1 = g1.map(plt.plot, alpha=1)\n",
    "g1 = g1.add_legend()\n",
    "\n",
    "g2 = sns.PairGrid(data=train_FD003.reset_index().query('engine_id < 20') ,\n",
    "                 x_vars=[\"index\"],\n",
    "                 y_vars=['rul'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g2 = g2.map(plt.plot, alpha=1)\n",
    "g2 = g2.add_legend()\n",
    "\n",
    "g3 = sns.PairGrid(data=train_FD004.reset_index().query('engine_id < 20') ,\n",
    "                 x_vars=[\"index\"],\n",
    "                 y_vars=['rul'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g3 = g3.map(plt.plot, alpha=1)\n",
    "g3 = g3.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we can at least qualitatively get a first impression that all four traing data sets are of similar kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YfEPxGjLm5K"
   },
   "outputs": [],
   "source": [
    "# Visualize some sensor curves of some engines \n",
    "g = sns.PairGrid(data=train_FD001.query('engine_id < 5') ,\n",
    "                 x_vars=[\"rul\"],\n",
    "                 y_vars=['s1','s2'],\n",
    "                 hue=\"engine_id\", height=3, aspect=2.5)\n",
    "\n",
    "g = g.map(plt.plot, alpha=1)\n",
    "g = g.add_legend()\n",
    "\n",
    "# As shown in the figure, some sensors are not related to RUL. \n",
    "# The values of some sensors change with the state of the machine. \n",
    "# Visualization can help filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kbeakQcTv5n",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of maximum life cycle\n",
    "train_FD001[['engine_id', 'rul']].groupby('engine_id').apply(np.max)[\"rul\"].hist(bins=20)\n",
    "plt.xlabel(\"max life cycle\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for the other training data sets\n",
    "train_FD002[['engine_id', 'rul']].groupby('engine_id').apply(np.max)[\"rul\"].hist(bins=20)\n",
    "plt.xlabel(\"max life cycle\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "train_FD003[['engine_id', 'rul']].groupby('engine_id').apply(np.max)[\"rul\"].hist(bins=20)\n",
    "plt.xlabel(\"max life cycle\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "train_FD004[['engine_id', 'rul']].groupby('engine_id').apply(np.max)[\"rul\"].hist(bins=20)\n",
    "plt.xlabel(\"max life cycle\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though qualitatively still related, there is clearly a difference in distribution of max. life cycle in the four training data sets. We prepare box plots as another simple form of visualization to get an overview of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul001 = train_FD001[['engine_id', 'rul']].groupby('engine_id').apply(np.max)['rul'].rename('MLC FD001 Train')\n",
    "rul001.plot(kind='box')\n",
    "plt.show()\n",
    "\n",
    "rul002 = train_FD002[['engine_id', 'rul']].groupby('engine_id').apply(np.max)['rul'].rename('MLC FD002 Train')\n",
    "rul002.plot(kind='box')\n",
    "plt.show()\n",
    "\n",
    "rul003 = train_FD003[['engine_id', 'rul']].groupby('engine_id').apply(np.max)['rul'].rename('MLC FD003 Train')\n",
    "rul003.plot(kind='box')\n",
    "plt.show()\n",
    "\n",
    "rul004 = train_FD004[['engine_id', 'rul']].groupby('engine_id').apply(np.max)['rul'].rename('MLC FD004 Train')\n",
    "rul004.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the box plots, the mean of max. life cycle values of engines in the data sets varies. While FD001 and 002 train feature a mean of 200, the other ones show significantly larger means. All sets feature outliers, but especially FD003 and 004 train include some that are meaningfully about 400.\n",
    "\n",
    "Overall, we gain the insight that the training data sets are similar but we should expect the models applied on each most successfully to likely differ regarding their hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZPWL4IWVJFV"
   },
   "source": [
    "# Modeling the FD001 Data Set\n",
    "\n",
    "\n",
    "## I. 'Naive' Approach\n",
    "\n",
    "First, we try to model the regression problem by only looking at a single input time sample at a time.\n",
    "\n",
    "We will focus on four regression models for now: A Random Forest approach, a linear Lasso model, Logistic Regression and finally a Multilayer Perceptron regressor.\n",
    "\n",
    "For each approach, hyper parameter tuning was performed using a combination of automated (grid search) and manual (estimation from experience, comparison) techniques as is described in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwWNM2GQWE-Q"
   },
   "outputs": [],
   "source": [
    "# prepare the data and normalization\n",
    "train_y = train_FD001['rul']\n",
    "features = train_FD001.columns.drop(['engine_id', 'cycle', 'rul'])\n",
    "train_x = train_FD001[features]\n",
    "test_x = test_FD001[features]\n",
    "\n",
    "\n",
    "# z score normalization\n",
    "mean = train_x.mean()\n",
    "std = train_x.std()\n",
    "std.replace(0, 1, inplace=True)\n",
    "\n",
    "train_x = (train_x - mean) / std\n",
    "test_x = (test_x - mean) / std\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "x, y = shuffle(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNk2ycyuFrHq"
   },
   "source": [
    "Here only the values at each time point (cycle) are used to predict the RUL. Temporal relationship is ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest\n",
    "\n",
    "We first take a look at a RF regressor with default hyper parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alPz0At-SyVz"
   },
   "outputs": [],
   "source": [
    "# Random Forest with default Hyper parameters\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(x,y)\n",
    "rf_prediction = rf_model.predict(train_x)\n",
    "\n",
    "plt.plot(rf_prediction[:500], label=\"Prediction Random Forest Default\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From experience we know that Random Forest models can be easily tuned by looking at the n_estimators (the number of estimators) and max_features (the number of features to include at most) parameters in scikit.\n",
    "\n",
    "A grid search was performed using the following approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (No need to run in-line in the notebook, just for exlanation)\n",
    "# param_grid = {'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 17, 20, 25, 26, 27, 30, 35, 40]}\n",
    "\n",
    "# search = GridSearchCV(rf_model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=5, n_jobs=-1)\n",
    "# search.fit(x,y)\n",
    "\n",
    "# >>> Best result: max_features=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s use that result to create a better RF regressor than the default one. Generally, a higher number of regressors is better, we will use n_estimators=500 as a trade-off between model fit time and quality of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_impr = RandomForestRegressor(n_estimators=500, max_features=3)  # 3 was best, based on grid search\n",
    "rf_model_impr.fit(x,y)\n",
    "rf_prediction_impr = rf_model_impr.predict(train_x)\n",
    "\n",
    "plt.plot(rf_prediction[:500], label=\"Prediction Random Forest Default\")\n",
    "plt.plot(rf_prediction_impr[:500], label=\"Prediction Random Forest Improved\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually we can already see small differences based on the new hyper parameters, but only at the evaluation step can we see how much better the improved RF model performs overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lasso (CV) Model\n",
    "\n",
    "Our next candidate model is a linear Lasso approach, wich is directly provided by scikit with cross validation and therefore convenient for higher-dimensional data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDzgpXQcLGsC"
   },
   "outputs": [],
   "source": [
    "# Lasso model with default Hyper parameters\n",
    "ls_model = LassoCV()\n",
    "ls_model.fit(x,y)\n",
    "ls_prediction = ls_model.predict(train_x)\n",
    "\n",
    "plt.plot(ls_prediction[:500], label=\"Prediction LassoCV Default\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lasso models, we can say from experience that the most interesting parameter to tune is genereally alpha. We additionally perform manually guided best alpha search using the built-in cross validation in LassoCV as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_model_alt = LassoCV(alphas=[0.05, 0.2, 0.5, 0.6, 0.8, 1.0, 1.4, 1.8, 2.2, 2.6, 3.0, 4.0, 6.0])\n",
    "ls_model_alt.fit(x,y)\n",
    "ls_alt_prediction = ls_model_alt.predict(train_x)\n",
    "\n",
    "plt.plot(ls_prediction[:500], label=\"Prediction LassoCV Default\")\n",
    "plt.plot(ls_alt_prediction[:500], label=\"Prediction LassoCV Guided Alpha\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is directly visible from the plot, manually guiding the alpha values to be used during cross-validation didnâ€™t lead to notable differences, the model characteristics are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression\n",
    "\n",
    "(TBD but doesnâ€™t seem promising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I12xg2WDK0pD"
   },
   "source": [
    "### 4. Multilayer Perceptron Regressor\n",
    "\n",
    "Finnaly, we use the MLPRegressor provided by scikit to model the problem using a neural net model. We first use the default net with one hidden layer of 100 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_model = MLPRegressor()\n",
    "mlp_model.fit(x,y)\n",
    "mlp_prediction = mlp_model.predict(train_x)\n",
    "\n",
    "plt.plot(mlp_prediction[:500], label=\"Prediction MLP Default\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a warning that the model with default hyper parameters didnâ€™t converge, but at first sight, the result looks promising and we continue our search for a MLP model.\n",
    "\n",
    "First, we look at different general hyper parameters to tune using grid search:\n",
    "- The activation function used\n",
    "- The solver optimizing our MLP\n",
    "- The size of the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (No need to run in-line in the notebook, just for exlanation)\n",
    "# param_grid = [\n",
    "#         {\n",
    "#             'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "#             'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "#             'hidden_layer_sizes': [\n",
    "#              (10,),(20,),(30,),(40,),(50,),(60,),(70,),(80,),(90,),(100,),(110,), (120,),(130,),(140,)\n",
    "#              ]\n",
    "#         }\n",
    "#        ]\n",
    "\n",
    "# >>> Best result: relu, 120, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search confirmes that the default hyper parameters are well chosen in terms of the ones investigated above. Therefore, we take a look at other hyper parameters now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (No need to run in-line in the notebook, just for exlanation)\n",
    "# param_grid = [\n",
    "#     {'learning_rate_init': [0.01, 0.001, 0.0001, 0.00001],\n",
    "#     'max_iter': [100, 300, 600, 1000]}\n",
    "# ]\n",
    "\n",
    "# >>> Best results: 0.001, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search indicated that under these circumstances, even 100 iterations at a constant learning rate of 0.001 should be suffcient. We create this new model in the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_impr = MLPRegressor(learning_rate='constant', learning_rate_init=0.001, max_iter=100)\n",
    "mlp_model_impr.fit(x,y)\n",
    "mlp_impr_prediction = mlp_model.predict(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preliminary Model Comparison\n",
    "\n",
    "Before we evaluate models on the test data set, we take a look at how they compare to each other in terms of modelling the traning data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.plot(rf_prediction_impr[:500], label=\"Prediction Random Forest Improved\")\n",
    "plt.plot(ls_prediction[:500], label=\"Prediction LassoCV Default\")\n",
    "plt.plot(mlp_impr_prediction[:500], label=\"Prediction MLP Improved\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All 'naive' models seem to perform regression on the training data at least on a basic level, but we can only evaluate their true performance using a test data set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iQ_3EzOVeAe"
   },
   "source": [
    "## Evaluation on FD001 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ie-jLvidHZ9O"
   },
   "outputs": [],
   "source": [
    "# Since only the value at one time point is used, it can be seen that a lot of data in the test set is not used\n",
    "\n",
    "test_x['engine_id'] = test_FD001['engine_id']\n",
    "test_input = []\n",
    "for id in test_x['engine_id'].unique():\n",
    "  \n",
    "  test_input.append(test_x[test_x['engine_id']==id].iloc[-1,:-1].values)\n",
    "\n",
    "test_input = np.array(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJ1HI43iHZ65"
   },
   "outputs": [],
   "source": [
    "rf_test_prediction = rf_model_impr.predict(test_input)\n",
    "rf_rmse = np.sqrt(mean_squared_error(rf_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "\n",
    "print(\"The RMSE of random forest on test dataset FD001 is \",rf_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YW_6FmUHZ4T"
   },
   "outputs": [],
   "source": [
    "ls_test_prediction = ls_model.predict(test_input)\n",
    "ls_rmse = np.sqrt(mean_squared_error(ls_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "\n",
    "print(\"The RMSE of Lasso model on test dataset FD001 is \",ls_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multilayer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_impr_prediction = mlp_model_impr.predict(test_input)\n",
    "mlp_rmse = np.sqrt(mean_squared_error(mlp_impr_prediction, RUL_FD001.values.reshape(-1)))\n",
    "\n",
    "print(\"The RMSE of MLP model on test dataset FD001 is \", mlp_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myaoeDxY09PE"
   },
   "source": [
    "**Of these 'naive' results, all models perform similarly on the test set. However, none of the approaches (i.e. only looking at a single input sample at a time) leads to acceptable results, with the RSME remaining rather large.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Sliding Window Approach\n",
    "\n",
    "As we have seen, looking at a slingle input at a time does not work well. We instead try a sliding window approach, i.e. not only looking at a single input but including its k - 1 previous inputs as well, where k is a (typically small) integer variable to be explored later on.\n",
    "\n",
    "First, we set up a function to generate sliding window data sets of an arbitrary size k and constant stride 1. To achieve this, we append columns to the data set that are suffix with ...-tminusX where X is in 1..k-1. Missing input values at the beginnig of the sliding window data set are set to zero.\n",
    "\n",
    "In order to achieve efficient transformation of the data sets, we make use of pandas join operations of individual data frames: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_data(df_in, k):\n",
    "    df_out = df_in.copy() \n",
    "    df_master_copy = df_in.copy()\n",
    "\n",
    "    for i in reversed(range(k - 1)):\n",
    "        df_copy = df_master_copy.copy()\n",
    "\n",
    "        to_delete = k - i - 1\n",
    "        \n",
    "        # Delete last x rows in the local copy\n",
    "        df_copy = df_copy[:-to_delete]\n",
    "\n",
    "        # Insert x empty rows at the beginning\n",
    "        for j in range(to_delete):\n",
    "            df_copy = df_copy.append(pd.Series(name='0', dtype='float64'))\n",
    "            df_copy = df_copy.shift(periods=1)\n",
    "            df_copy = df_copy.reset_index(drop=True)\n",
    "\n",
    "        # Replace NaN values with zero\n",
    "        df_copy = df_copy.fillna(0)\n",
    "        \n",
    "        # Rename columns: Use original name and add ...-tminusX\n",
    "        new_cols = []\n",
    "        for col_orig in df_copy.columns:\n",
    "            new_cols.append(col_orig + \"-tminus\" + str(to_delete))\n",
    "\n",
    "        df_copy.columns = new_cols\n",
    "\n",
    "        # Append columns to result data frame\n",
    "        df_out = df_copy.join(df_out)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now letâ€™s use the new function to create a sliding window test and validation set, based on FD0001. We use k = 20 to start out, i.e. sliding window size of 20 and take a look at the new data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sw20 = sliding_window_data(train_x, 20)\n",
    "\n",
    "if 'engine_id' in test_x:\n",
    "    test_x = test_x.drop(['engine_id'], axis=1)  # Don't forget to drop the column added for testing previously!\n",
    "test_x_sw20 = sliding_window_data(test_x, 20)\n",
    "\n",
    "print(\"-> Shapes of the new data frames:\", train_x_sw20.shape, test_x_sw20.shape)\n",
    "\n",
    "train_x_sw20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sw20.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first rows contain many zero values due to the padding strategy applied, but the temporaly shifted data is fully present in the rows starting out from the 20th row and down.\n",
    "\n",
    "We also prepare sliding window data sets with k = 50 and k = 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sw50 = sliding_window_data(train_x, 50)\n",
    "test_x_sw50 = sliding_window_data(test_x, 50)\n",
    "print(\"-> Shapes of the new data frames:\", train_x_sw50.shape, test_x_sw50.shape)\n",
    "print(\"Memory usage:\", round(test_x_sw50.memory_usage(index=True).sum() / (1024 ** 2), 0), \"MB\")\n",
    "\n",
    "#train_x_sw75 = sliding_window_data(train_x, 75)    # No need to run, just for illustration!\n",
    "#test_x_sw75 = sliding_window_data(test_x, 75)\n",
    "#print(\"-> Shapes of the other new data frames:\", train_x_sw50.shape, test_x_sw50.shape)\n",
    "#print(\"Memory usage:\", round(test_x_sw75.memory_usage(index=True).sum() / (1024 ** 2), 0), \"MB\")\n",
    "\n",
    "x_sw20, y_sw20 = shuffle(train_x_sw20, train_y)\n",
    "x_sw50, y_sw50 = shuffle(train_x_sw50, train_y)\n",
    "#x_sw75, y_sw75 = shuffle(train_x_sw75, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.) Lasso Model\n",
    "\n",
    "We use a linear LassoCV model (previously the second model applied) with built-in cross-validation as a first simple approach on our new sliding window data sets, to see which results we can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_model_sw20 = LassoCV()\n",
    "ls_model_sw20.fit(x_sw20, y_sw20)\n",
    "ls_prediction_sw20 = ls_model_sw20.predict(train_x_sw20)\n",
    "\n",
    "ls_model_sw50 = LassoCV()\n",
    "ls_model_sw50.fit(x_sw50, y_sw50)\n",
    "ls_prediction_sw50 = ls_model_sw50.predict(train_x_sw50)\n",
    "\n",
    "plt.plot(train_FD001[\"rul\"][:1000], label=\"Train RUL\")\n",
    "plt.plot(ls_prediction[:1000], label=\"Prediction Naive LassoCV\")\n",
    "plt.plot(ls_prediction_sw20[:1000], label=\"Prediction LS SW-20\")\n",
    "plt.plot(ls_prediction_sw50[:1000], label=\"Prediction LS SW-50\")\n",
    "#plt.plot(ls_prediction_sw100[:500], label=\"Prediction LS SW-100\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately observe qualitative differences in the fitting characteristics between the navive Lasso model and the two sliding window approaches.\n",
    "\n",
    "Letâ€™s see what this relates to on the validation data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window k=20 model\n",
    "test_x_sw20['engine_id'] = test_FD001['engine_id']\n",
    "test_input = []\n",
    "for id in test_x_sw20['engine_id'].unique():\n",
    "    test_input.append(test_x_sw20[test_x_sw20['engine_id']==id].iloc[-1,:-1].values)\n",
    "\n",
    "test_input = np.array(test_input)\n",
    "\n",
    "ls_test_prediction = ls_model_sw20.predict(test_input)\n",
    "ls_rmse = np.sqrt(mean_squared_error(ls_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "print(\"The RMSE of Lasso model SW-20 on test dataset FD001 is \", ls_rmse)\n",
    "\n",
    "# Sliding window k=50 model\n",
    "test_x_sw50['engine_id'] = test_FD001['engine_id']\n",
    "test_input = []\n",
    "for id in test_x_sw50['engine_id'].unique():\n",
    "    test_input.append(test_x_sw50[test_x_sw50['engine_id']==id].iloc[-1,:-1].values)\n",
    "\n",
    "test_input = np.array(test_input)\n",
    "\n",
    "ls_test_prediction = ls_model_sw50.predict(test_input)\n",
    "ls_rmse = np.sqrt(mean_squared_error(ls_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "print(\"The RMSE of Lasso model SW-50 on test dataset FD001 is \", ls_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediatly observe that a larger sliding window for the lasso model leads to better results on the evaluation data. Therefore we can assume that likely, for the other models this holds true as well.\n",
    "Based on this assumption, we will only train models with k = 50 from now on. We will not use larger sliding windows, as the memory needs and transform times are inconvenient in context of this notebook document, but it was  observed that generally larger sliding windows result in better results when evaluating the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest\n",
    "\n",
    "Now letâ€™s take a look at the random forest again. With grid search, max_features = 100 was determined to be a well suited parameter and n_estimators = 500 is again used as a trade-off between computing time available aand quality of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with default Hyper parameters\n",
    "rf_model_sw50 = RandomForestRegressor(n_estimators=500, max_features=100)\n",
    "rf_model_sw50.fit(x_sw50, y_sw50)\n",
    "rf_prediction = rf_model_sw50.predict(train_x_sw50)\n",
    "\n",
    "plt.plot(rf_prediction[:500], label=\"Prediction Random SW-50\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate\n",
    "rf_test_prediction = ls_model_sw50.predict(test_input)\n",
    "ls_rmse = np.sqrt(mean_squared_error(ls_test_prediction, RUL_FD001.values.reshape(-1)))\n",
    "print(\"The RMSE of RF model SW-50 on test dataset FD001 is \", ls_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression\n",
    "\n",
    "(TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multilayer Perceptron Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_sw50 = MLPRegressor(learning_rate='constant', learning_rate_init=0.001, max_iter=100)\n",
    "mlp_model_sw50.fit(x_sw50, y_sw50)\n",
    "mlp_prediction = mlp_model_sw50.predict(train_x_sw50)\n",
    "\n",
    "plt.plot(mlp_prediction[:500], label=\"Prediction MLP SW-50\")\n",
    "plt.plot(train_FD001[\"rul\"][:500], label=\"Train RUL\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the FD002 Data Set\n",
    "\n",
    "Now we are going to repeat the process from FD001 on the other data sets. Because sliding window beat the 'naive' approach by far, we are only going to use sliding window regression going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the FD003 Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the FD004 Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We have determined that modelling the regression problem was most successfully done using the sliding window approach. As a trade-off between quality of modelling and the computing time and memory required, we have chose to work with sliding windows of size k = 50 at most. Genereally, we assume that larger sliding window sizes would however result in even better perfromance the evaluation data, as times seqeunces usually are well suited to this.\n",
    "At each step of modelling, we applied the useful capabilities of scikit grid search and cross validation to come up with well suited parameters to speed up hyper parameter selection.\n",
    "\n",
    "Overview of the best models ans their RMSE on the evaluation data sets:\n",
    "\n",
    "| FD001 | FD002 | FD003 | FD004 |\n",
    "|:-----:|:-----:|:-----:|:-----:|\n",
    "|                               |\n",
    "|                               |\n",
    "\n",
    "In General, we could learn much from the previous tasks of task set 1 and applied them all in task 9, regarding data set exploratin, visualization, model selection, hyper parameter tuning and of course evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C-MAPSS RUL Estimation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
